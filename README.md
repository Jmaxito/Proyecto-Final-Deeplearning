# ClasificaciÃ³n de Malezas y Cultivo de Sorgo con Deep Learning  
Modelos CNN y ResNet18 desde cero

Este repositorio contiene el pipeline completo para entrenar, evaluar y comparar modelos de **clasificaciÃ³n de imÃ¡genes agrÃ­colas**, utilizando el dataset **SorghumWeedDataset_Classification**, el cual contiene imÃ¡genes de:

- **Clase 0** â€“ PlÃ¡ntulas de sorgo  
- **Clase 1** â€“ Pastos  
- **Clase 2** â€“ Malezas de hoja ancha  

Se implementaron dos arquitecturas desde cero:

1. **CNN desarrollada en Keras**  
2. **ResNet18 desarrollada manualmente en PyTorch (sin transfer learning)**  

El objetivo es evaluar el rendimiento de arquitecturas simples vs. redes profundas sin pesos preentrenados en un dataset moderado (~4,300 imÃ¡genes).

---

## Estructura del Dataset
El dataset se compone de 4312 imagenes, Train:3019, Val:862, Test:431. Cada una contiene las clases: Calss0_Sorghum, Class1_Grass, Class2_BroadLeafWeed
El dataset debe organizarse en formato estÃ¡ndar de clasificaciÃ³n:

â”œâ”€â”€ train/

â”‚ â”œâ”€â”€ class0/

â”‚ â”œâ”€â”€ class1/

â”‚ â””â”€â”€ class2/

â”œâ”€â”€ val/

â”‚ â”œâ”€â”€ class0/

â”‚ â”œâ”€â”€ class1/

â”‚ â””â”€â”€ class2/

â””â”€â”€ test/

â”œâ”€â”€ class0/

â”œâ”€â”€ class1/

â””â”€â”€ class2/

Cada imagen fue redimensionada a **224 Ã— 224 px**.

---

# Modelos Utilizados

##  1. CNN (Keras â€“ Training from Scratch)

Arquitectura simple con:
- Convoluciones 2D
- MaxPooling
- Dropout
- Capa densa final softmax

##  2. ResNet18 (PyTorch â€“ Training from Scratch)

ImplementaciÃ³n manual de:
- BasicBlock (bloques residuales)
- Arquitectura original (2 bloques por etapa)
- Sin pesos preentrenados de ImageNet

---

#  Resultados

Los experimentos se realizaron en Google Colab (GPU cuando disponible).  
Los resultados reportados son los obtenidos tras el entrenamiento completo en el *set de prueba*.

##  MÃ©tricas Finales

###  CNN (Keras)
- **Accuracy entrenamiento:** 0.9038  
- **Loss entrenamiento:** 0.2962  
- **Accuracy test:** 0.8724  
- **Loss test:** 0.3907  

###  ResNet18 (PyTorch desde cero)
- **Accuracy test:** 0.8353  
- **Loss test:** 0.4348  

---

#  Tabla Comparativa

| CaracterÃ­stica | CNN (Keras) | ResNet18 (PyTorch â€“ desde cero) |
|----------------|-------------|----------------------------------|
| Arquitectura | CNN simple | ResNet18 completa |
| Entrenamiento | Desde cero | Desde cero |
| Preentrenamiento | âŒ No | âŒ No |
| Accuracy (test) | **0.8724** | 0.8353 |
| Loss (test) | **0.3907** | 0.4348 |
| TamaÃ±o del modelo | PequeÃ±o | Grande |
| Riesgo de Overfitting | Bajo | Medio |
| Velocidad de entrenamiento | Lenta | RÃ¡pida |
| GeneralizaciÃ³n | **Alta** | Buena |
| Complejidad | Baja | Alta |

---

#  Conclusiones

- La **CNN**, a pesar de ser mÃ¡s pequeÃ±a y simple, logrÃ³ **mejor generalizaciÃ³n** que ResNet18 desde cero.  
- La **ResNet18** demostrÃ³ ser potente, pero al no utilizar transfer learning requiere mÃ¡s datos y regularizaciÃ³n para alcanzar su mÃ¡ximo rendimiento.
- Esto confirma que en datasets agrÃ­colas de tamaÃ±o medio, **las arquitecturas pequeÃ±as desde cero pueden superar a redes profundas no preentrenadas**.

Se recomienda probar este proyecto con:
- Transfer Learning en ResNet18 y MobileNetV2  
- Data augmentation avanzado  
- Mezcla de tÃ©cnicas como CutMix o MixUp  

---

# ğŸš€ CÃ³mo Reproducir el Proyecto

### 1. Clonar el repositorio:

```bash
git clone https://github.com/usuario/tu-repo.git
cd tu-repo
